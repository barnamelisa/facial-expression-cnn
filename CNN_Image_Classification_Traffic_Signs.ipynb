{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd050ce",
   "metadata": {},
   "source": [
    "# Clasificare Imagini cu Retele Neuronale Convolutionale\n",
    "\n",
    "În acest notebook, vom crea două modele CNN pentru a clasifica imagini cu semne de circulație. Vom testa diferiți optimizatori și dimensiuni de kernel și vom analiza performanța modelelor cu diverse metrici. La final, vom folosi SHAP pentru interpretarea deciziilor modelului."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4701c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importam librariile necesare pentru construire, antrenare, evaluare si interpretare model CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# ENUNT:\n",
    "# Construim o retea neuronala convolutionala care poate clasifica intre 2 si 10 clase,\n",
    "# pe o problema la alegerea noastra (ex: emotii, animale, mancare etc).\n",
    "# Vom construi 2 modele CNN:\n",
    "#   1) cu 2 layere convolutie + 1 de iesire\n",
    "#   2) cu 4-6 layere convolutie + 1 de iesire\n",
    "# Ambele modele vor contine:\n",
    "# - activare ReLU\n",
    "# - MaxPooling pentru reducerea dimensiunii spatiale\n",
    "# - Dropout sau BatchNormalization pentru generalizare mai buna\n",
    "# - un fully connected layer (Dense)\n",
    "# - softmax la iesire pentru clasificare multi-clasa\n",
    "#\n",
    "# Vom incerca optimizatori SGD si Adam si kernel-uri 3x3 si 5x5.\n",
    "# Vom evalua performanta cu train/val accuracy, confusion matrix, precision, recall, F1-score,\n",
    "# si vom afisa curbele de loss si acuratete.\n",
    "# De asemenea, vom folosi SHAP pentru interpretarea predictiilor modelului.\n",
    "# ---------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8dfad8",
   "metadata": {},
   "source": [
    "## Încărcarea și preprocesarea datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Functie pentru incarcare si preprocesare date\n",
    "# ----------------------------\n",
    "\n",
    "def load_data(data_dir, img_size=(48, 48)):\n",
    "    \"\"\"\n",
    "    Incarca imaginile din folderele cu clase (ex: caini, pisici, trist, fericit etc).\n",
    "    Redimensioneaza imaginile la dimensiunea img_size.\n",
    "    Normalizare pixeli intre 0 si 1.\n",
    "    Returneaza matricea de imagini X, etichetele y (one-hot encoded) si dictionarul label_map.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    labels = os.listdir(data_dir)\n",
    "    label_map = {label: idx for idx, label in enumerate(labels)}  # fiecare clasa primeste un index numeric\n",
    "    \n",
    "    for label in labels:\n",
    "        files = glob.glob(os.path.join(data_dir, label, '*.png'))  # sau jpg, in functie de dataset\n",
    "        for file in files:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)  # incarcare grayscale\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = np.expand_dims(img, axis=-1)  # adauga canalul      \n",
    "            X.append(img)\n",
    "            y.append(label_map[label])             \n",
    "    \n",
    "    X = np.array(X) / 255.0                     \n",
    "    y = np.array(y)\n",
    "    y_cat = to_categorical(y)                     \n",
    "    return X, y_cat, label_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96b5be",
   "metadata": {},
   "source": [
    "## Model 1: CNN simplu (2 layere de convoluție)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b194760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Model 1: CNN simplu cu 2 layere de convolutie + 1 de iesire\n",
    "# ----------------------------\n",
    "\n",
    "def build_simple_cnn(input_shape, num_classes, kernel_size=(3,3)):\n",
    "    \"\"\"\n",
    "    Modelul simplu respecta cerinta de 2 layere convolutie + 1 strat de iesire softmax.\n",
    "    Foloseste activare ReLU, MaxPooling, Dropout si un fully connected layer.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, kernel_size, activation='relu', input_shape=input_shape),  # strat convolutie 1 cu ReLU\n",
    "        layers.MaxPooling2D((2, 2)),  # reducere spatiala\n",
    "        layers.Conv2D(64, kernel_size, activation='relu'),  # strat convolutie 2 cu ReLU\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),  # transformare matrice 2D -> vector 1D pentru dense layer\n",
    "        layers.Dense(128, activation='relu'),  # fully connected cu ReLU\n",
    "        layers.Dropout(0.5),  # regularizare Dropout pentru a evita overfitting\n",
    "        layers.Dense(num_classes, activation='softmax')  # strat de iesire cu softmax pentru clasificare multi-clasa\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d05094",
   "metadata": {},
   "source": [
    "## Model 2: CNN complex (4-6 layere de convoluție)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Model 2: CNN complex cu 4 layere de convolutie + 1 de iesire\n",
    "# ----------------------------\n",
    "\n",
    "def build_complex_cnn(input_shape, num_classes, kernel_size=(3,3)):\n",
    "    \"\"\"\n",
    "    Modelul complex respecta cerinta de 4-6 layere convolutie + 1 strat de iesire.\n",
    "    Include BatchNormalization pentru stabilizare, Dropout pentru regularizare,\n",
    "    ReLU, MaxPooling, un fully connected mare si softmax la iesire.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, kernel_size, activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size, activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, kernel_size, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, kernel_size, activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9488b",
   "metadata": {},
   "source": [
    "## Antrenare și comparare modele cu Adam și SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408aa9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Functie de antrenare a modelului cu optimizator specificat\n",
    "# ----------------------------\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, optimizer, epochs=10):\n",
    "    \"\"\"\n",
    "    Compileaza si antreneaza modelul folosind optimizerul specificat (SGD sau Adam).\n",
    "    Functia de pierdere folosita este categorical_crossentropy, specifica clasificarii multi-clasa.\n",
    "    Returneaza istoricul antrenamentului.\n",
    "    \"\"\"\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=32)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e8994",
   "metadata": {},
   "source": [
    "## Evaluare performanță"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Evaluare model: raport clasificare si matrice confuzie\n",
    "# ----------------------------\n",
    "\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Calculeaza predictiile modelului, afiseaza raportul de clasificare\n",
    "    (precision, recall, f1-score) si matricea de confuzie (heatmap).\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    print(classification_report(y_true, y_pred_classes))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25cd40",
   "metadata": {},
   "source": [
    "## Plot evoluție Loss și Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Afisare grafice pierdere si acuratete\n",
    "# ----------------------------\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Afiseaza curbele de evolutie a pierderii (loss) si acuratetii (accuracy)\n",
    "    pe setul de antrenament si validare, pentru analiza performantelor.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Curba pierderii (Loss)')\n",
    "    plt.xlabel('Epoca')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Curba acuratetii (Accuracy)')\n",
    "    plt.xlabel('Epoca')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e555480",
   "metadata": {},
   "source": "## Interpretare cu SHAP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Interpretare cu SHAP\n",
    "# ----------------------------\n",
    "\n",
    "def interpret_with_shap(model, X_train, X_val):\n",
    "    \"\"\"\n",
    "    Folosim SHAP pentru a interpreta deciziile modelului.\n",
    "    Selectam un subset de imagini ca background si afisam explicatii vizuale\n",
    "    pentru 2-3 imagini din setul de validare.\n",
    "    \"\"\"\n",
    "    background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "    explainer = shap.GradientExplainer((model, model.input), background)\n",
    "    shap_values = explainer.shap_values(X_val[:3])\n",
    "    shap.image_plot(shap_values, X_val[:3])\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Rulare exemplu",
   "id": "855d433034d59787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ----------------------------\n",
    "# Exemplu complet de rulare\n",
    "# ----------------------------\n",
    "\n",
    "data_dir = 'data'  # folderul cu date: fiecare clasa are propriul subfolder\n",
    "img_size = (32, 32)  # dimensiune uniforma pentru imagini\n",
    "\n",
    "# Incarcam si preprocesam datele\n",
    "X, y, label_map = load_data(data_dir, img_size)\n",
    "print(\"Clasele detectate:\", label_map)\n",
    "\n",
    "# Impartim datele in train si validare\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "# Construim modelul simplu cu kernel 3x3 si optimizator Adam\n",
    "model_simple = build_simple_cnn(input_shape, num_classes, kernel_size=(3,3))\n",
    "history_simple = train_model(model_simple, X_train, y_train, X_val, y_val, optimizer=Adam(), epochs=10)\n",
    "\n",
    "# Construim modelul complex cu kernel 5x5 si optimizator SGD\n",
    "model_complex = build_complex_cnn(input_shape, num_classes, kernel_size=(5,5))\n",
    "history_complex = train_model(model_complex, X_train, y_train, X_val, y_val, optimizer=SGD(), epochs=10)\n",
    "\n",
    "# Evaluam si afisam performanta modelului simplu\n",
    "print(\"Evaluare model simplu:\")\n",
    "evaluate_model(model_simple, X_val, y_val)\n",
    "plot_history(history_simple)\n",
    "\n",
    "# Evaluam si afisam performanta modelului complex\n",
    "print(\"Evaluare model complex:\")\n",
    "evaluate_model(model_complex, X_val, y_val)\n",
    "plot_history(history_complex)\n",
    "\n",
    "# Interpretare SHAP pentru modelul simplu\n",
    "interpret_with_shap(model_simple, X_train, X_val)"
   ],
   "id": "fd44c92b8a15e6a4"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
